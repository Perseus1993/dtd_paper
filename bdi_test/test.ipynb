{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from bdi_test.sf import load_graph\n",
    "import random\n",
    "\n",
    "# 定义OD对\n",
    "od_pairs = [\n",
    "    (14, 4), (14, 5), (15, 6), (15, 8),  # 更多的OD对可以根据需求添加\n",
    "    (22, 9), (22, 10), (23, 11), (23, 16)\n",
    "]\n",
    "G, pos_coord, pos_xy,sioux_falls_df = load_graph()"
   ],
   "id": "d2587011a87d0cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def find_all_paths(graph, origin, destination, k=None):\n",
    "    \"\"\"找到从origin到destination的所有可行路径，或前k条最短路径\"\"\"\n",
    "    if k is not None:\n",
    "        # 使用K条最短路径\n",
    "        return list(nx.shortest_simple_paths(graph, origin, destination, weight='length'))[:k]\n",
    "    else:\n",
    "        # 找到所有简单路径\n",
    "        return list(nx.all_simple_paths(graph, origin, destination))\n",
    "\n",
    "def precompute_path_combinations(graph, od_pairs, k=None):\n",
    "    \"\"\"预先计算指定OD对的所有可行路径组合\"\"\"\n",
    "    path_combinations = {}\n",
    "\n",
    "    for origin, destination in od_pairs:\n",
    "        paths = find_all_paths(graph, origin, destination, k)\n",
    "        path_combinations[(origin, destination)] = paths\n",
    "\n",
    "    return path_combinations\n",
    "\n",
    "# 将 MultiDiGraph 转换为 DiGraph\n",
    "G_simple = nx.DiGraph(G)\n",
    "\n",
    "# 继续使用 G_simple 进行路径计算\n",
    "path_combinations = precompute_path_combinations(G_simple, od_pairs)"
   ],
   "id": "50f27609716135b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "path_combinations[(14, 4)]",
   "id": "c59340800c40b8f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exploration_rate = 0.01  # 探索行为的概率\n",
    "memory_level = 0.8  # ψ: 旅行者的记忆水平，控制权重衰减\n",
    "class BDI_Agent:\n",
    "    next_id = 0\n",
    "    def __init__(self, learning_rate,initial_aspiration, paths, origin, destination):\n",
    "        self.id = BDI_Agent.next_id\n",
    "        BDI_Agent.next_id += 1\n",
    "        self.beliefs = {path: 1 / len(paths) for path in paths}  # 初始化为均匀概率分布\n",
    "        self.intention = random.choice(list(self.beliefs.keys()))  # 初始化随机选择一条路径\n",
    "        self.travel_history = {p: [] for p in paths}  # 记录每条路径的旅行时间历史\n",
    "        self.learning_rate = learning_rate  # 学习速率，控制信念更新的速度\n",
    "        self.aspiration = initial_aspiration  # 初始化全局 Aspiration\n",
    "        self.origin = origin  # 分配的起点\n",
    "        self.destination = destination  # 分配的终点\n",
    "        self.current_location = origin  # 当前的位置，开始时在起点\n",
    "\n",
    "    def calculate_stimulus(self, PT, current_path):\n",
    "        \"\"\"根据全局 Aspiration 和 PT 计算刺激值\"\"\"\n",
    "        diff = self.aspiration - PT  # 使用全局 Aspiration 计算差异\n",
    "\n",
    "        if diff >= 0:\n",
    "            # 正面反馈：当前路径表现优于预期，计算最大可能的收益\n",
    "            max_benefit = max([self.aspiration - self.calculate_PT(p) for p in paths if p != current_path])\n",
    "            stimulus = diff / max(max_benefit, 1e-10)  # 防止除以零\n",
    "        else:\n",
    "            # 负面反馈：当前路径表现不如预期，计算最小可能的损失\n",
    "            min_loss = min([self.aspiration - self.calculate_PT(p) for p in paths if p != current_path])\n",
    "            stimulus = diff / max(abs(min_loss), 1e-10)  # 防止除以零\n",
    "\n",
    "        return stimulus\n",
    "\n",
    "    def calculate_PT(self, path):\n",
    "        \"\"\"计算指定路径的感知旅行时间（PT）\"\"\"\n",
    "        times = self.travel_history[path]\n",
    "        if times:\n",
    "            # 使用记忆衰减权重计算感知旅行时间\n",
    "            weights = [memory_level ** (len(times) - 1 - j) for j in range(len(times))]\n",
    "            PT = sum(t * w for t, w in zip(times, weights)) / sum(weights)\n",
    "        else:\n",
    "            # 如果没有历史数据，使用路径的自由流时间作为PT\n",
    "            PT = paths[path]['free_flow_time']\n",
    "        return PT\n",
    "\n",
    "    def update_aspiration(self, PT):\n",
    "        \"\"\"基于最近的 PT 动态更新全局 Aspiration\"\"\"\n",
    "        self.aspiration = self.aspiration + self.learning_rate * (PT - self.aspiration)\n",
    "\n",
    "    def update_probabilities(self, stimulus):\n",
    "        for path in self.beliefs:\n",
    "            if path == self.intention:\n",
    "                if stimulus >= 0:\n",
    "                    self.beliefs[path] += (1 - self.beliefs[path]) * self.learning_rate * stimulus\n",
    "                else:\n",
    "                    self.beliefs[path] -= self.beliefs[path] * self.learning_rate * abs(stimulus)\n",
    "            else:\n",
    "                self.beliefs[path] -= self.learning_rate * abs(stimulus) * self.beliefs[path]\n",
    "\n",
    "            # 避免信念值为负\n",
    "            self.beliefs[path] = max(0, self.beliefs[path])\n",
    "\n",
    "        # 确保信念总和为正\n",
    "        total_belief = sum(self.beliefs.values())\n",
    "        if total_belief == 0:\n",
    "            # 如果总和为零，重新分配信念值\n",
    "            self.beliefs = {path: 1 / len(paths) for path in self.beliefs}\n",
    "            total_belief = 1\n",
    "\n",
    "        # 确保概率总和为1\n",
    "        for path in self.beliefs:\n",
    "            self.beliefs[path] /= total_belief\n",
    "\n",
    "    def choose_path(self):\n",
    "        # 引入探索行为\n",
    "        if random.random() < exploration_rate:\n",
    "            self.intention = random.choice(list(self.beliefs.keys()))\n",
    "        else:\n",
    "            self.intention = random.choices(list(self.beliefs.keys()), weights=list(self.beliefs.values()))[0]\n",
    "        return self.intention\n",
    "    \n",
    "    def calculate_total_travel_time(self, graph, path_edges):\n",
    "        \"\"\"计算一条路径的总旅行时间\"\"\"\n",
    "        total_travel_time = 0\n",
    "        for edge in path_edges:\n",
    "            u, v, k = edge\n",
    "            if graph.has_edge(u, v, k):\n",
    "                flow = graph[u][v][k].get('flow', 0)\n",
    "                capacity = graph[u][v][k].get('capacity', 1)  # 避免除零错误\n",
    "                free_flow_time = graph[u][v][k].get('free_flow_time', 0)  # 默认值为0\n",
    "                travel_time = free_flow_time * (1 + 0.15 * (flow / capacity) ** 4)\n",
    "                total_travel_time += travel_time\n",
    "            else:\n",
    "                print(f\"Warning: Edge {edge} not found in the graph.\")\n",
    "                total_travel_time += float('inf')  # 使用无穷大表示不可达路径\n",
    "        return total_travel_time\n",
    "\n",
    "    def move_to_destination(self, graph):\n",
    "        \"\"\"执行一次OD旅行\"\"\"\n",
    "        chosen_path = self.choose_path()\n",
    "        path_edges = self.paths[chosen_path]\n",
    "        total_travel_time = self.calculate_total_travel_time(graph, path_edges)\n",
    "\n",
    "        # 更新当前路径的旅行历史\n",
    "        self.travel_history[chosen_path].append(total_travel_time)\n",
    "        \n",
    "        # 更新信念和aspiration\n",
    "        PT = self.calculate_PT(chosen_path)\n",
    "        stimulus = self.calculate_stimulus(PT, chosen_path)\n",
    "        self.update_probabilities(stimulus)\n",
    "        self.update_aspiration(PT)\n",
    "\n",
    "        # 移动到目的地\n",
    "        self.current_location = self.destination\n",
    "        \n",
    "        # 回到起点，为下一次旅行做准备\n",
    "        self.reset_to_origin()\n",
    "\n",
    "        return chosen_path, total_travel_time\n",
    "\n",
    "    \n",
    "    def reset_to_origin(self):\n",
    "        \"\"\"回到起点\"\"\"\n",
    "        self.current_location = self.origin"
   ],
   "id": "80b08950eaebef24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 初始化路径和Agent\n",
    "paths = list(sioux_falls_df['edge'])\n",
    "\n",
    "# 初始化多个Agent\n",
    "agents = [BDI_Agent(learning_rate=0.1, initial_aspiration=10, paths=paths, \n",
    "                    origin=origin, destination=destination) \n",
    "          for origin, destination in od_pairs]\n",
    "\n",
    "# 模拟多个Episode\n",
    "for episode in range(10):\n",
    "    for agent in agents:\n",
    "        chosen_path, total_travel_time = agent.move_to_destination(G)\n",
    "        \n",
    "        # 更新路径上的流量数据\n",
    "        for edge in paths[chosen_path]:\n",
    "            u, v, k = edge\n",
    "            G[u][v][k]['flow'] = G[u][v][k].get('flow', 0) + 1\n"
   ],
   "id": "2013253b4e9976e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def simulate_agents_movement(agents, graph):\n",
    "    # 1. 总结 Agent 的路径选择\n",
    "    path_flows = {path: 0 for path in graph.edges(keys=True)}\n",
    "    agent_choices = []\n",
    "\n",
    "    for agent in agents:\n",
    "        chosen_path = agent.choose_path()\n",
    "        path_edges = agent.paths[chosen_path]\n",
    "        agent_choices.append((agent, chosen_path, path_edges))\n",
    "\n",
    "        # 统计每条路径上的流量\n",
    "        for edge in path_edges:\n",
    "            path_flows[edge] += 1\n",
    "\n",
    "    # 2. 计算 BPR 函数并更新路径的旅行时间\n",
    "    for edge, flow in path_flows.items():\n",
    "        u, v, k = edge\n",
    "        capacity = graph[u][v][k].get('capacity', 1)\n",
    "        free_flow_time = graph[u][v][k].get('free_flow_time', 0)\n",
    "        \n",
    "        # 使用BPR函数计算实际通行时间\n",
    "        travel_time = free_flow_time * (1 + 0.15 * (flow / capacity) ** 4)\n",
    "        graph[u][v][k]['travel_time'] = travel_time\n",
    "\n",
    "    # 3. 计算每个 Agent 的行走时间，并更新其信念和aspiration\n",
    "    for agent, chosen_path, path_edges in agent_choices:\n",
    "        total_travel_time = agent.calculate_total_travel_time(graph, path_edges)\n",
    "        \n",
    "        # 更新Agent的旅行历史\n",
    "        agent.travel_history[chosen_path].append(total_travel_time)\n",
    "        \n",
    "        # 计算PT和刺激值，更新信念和aspiration\n",
    "        PT = agent.calculate_PT(chosen_path)\n",
    "        stimulus = agent.calculate_stimulus(PT, chosen_path)\n",
    "        agent.update_probabilities(stimulus)\n",
    "        agent.update_aspiration(PT)\n",
    "\n",
    "        # Agent 完成旅行，准备下一次旅行\n",
    "        agent.reset_to_origin()\n",
    "\n",
    "    return path_flows  # 返回每条路径的流量\n"
   ],
   "id": "3a382be4e97fdd2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
